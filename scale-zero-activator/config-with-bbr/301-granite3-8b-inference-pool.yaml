apiVersion: inference.networking.x-k8s.io/v1alpha2
kind: InferencePool
metadata:
  name: granite3-8b-epp
spec:
  extensionRef:
    failureMode: FailClose
    group: ""
    kind: Service
    name: granite3-8b-epp
    portNumber: 9002
  selector:
    llm-d.ai/model: "granite3-8b"
    llm-d.ai/inferenceServing: "true"
  targetPortNumber: 8000
